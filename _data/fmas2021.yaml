### SCHEDULE ###


show_schedule : true
schedule-day_one:
- time:  13:00 - 13:30
  intro: true
  name:  "Welcome and Introduction"

- time: 13:30 - 14:30
  invited: true
  name: " Invited Talk: Clare Dixon - Help or Hazard: Towards Verifying Autonomous Robot Systems"
  
- time: 14:30 - 15:00
  break: true
  name: "BREAK"
  
- time:  15:00 - 15:30
  name:   "Extending Urban Multi-Lane Spatial Logic to Formalise Road Junction Rules - Maike Schwammberger and Gleifer Alves"
  
- time: 15:30 - 16:00
  name:  "Simulation and Model checking for real-time overtaking planning - Daumantas Pagojus, Alice Miller, Bernd Porr and Ivaylo Valkov "
  
- time:  16:00 - 16:30
  name:   "Towards Partial Monitoring: It is Always too Soon to Give Up - Angelo Ferrando and Rafael C. Cardoso"

- time: 16:30 - 17:00
  break : true
  name:  "BREAK"

- time: 17:00 - 17:30
  name: "Complete Agent-driven Model-based System Testing for Autonomous Systems - Kerstin Eder, Wen-Ling Huang and Jan Peleska "
  
- time: 17:30 - 18:00
  name:  " Formal Guarantees of Timely Progress for Distributed Knowledge Propagation - Saswata Paul, Stacy Patterson and Carlos A. Varela"
  
- time:  18:00 - 18:30
  name:  "QuantifyML: How good is my machine learning model? - Muhammad Usman, Divya Gopinath and Corina S. Pasareanu"
  
- time: 18:30
  close: true
  name: "Day One Close"

schedule-day_two:
- time:  13:00 - 13:30
  intro: true
  name:  "Welcome and Introduction"

- time: 13:30 - 14:00
  name: " Complete Test of Synthesised Safety Supervisors for Robots and Autonomous Systems - Mario Gleirscher and Jan Peleska"
  
- time: 14:00 - 14:30
  name:    "Improving Online Railway Deadlock Detection using a Partial Order Reduction - Bjørnar Luteberget"
  
- time:  14:30 - 15:00
  name:   "Strategy Synthesis for Safe and Optimized Online Control of Steerable Needles - Sascha Lehmann, Antje Rogalla, Maximilian Neidhardt, Alexander Schlaefer and Sibylle Schupp"

- time: 15:00 - 15:30
  break : true
  name:  "BREAK"

- time: 15:30 - 16:00
  name:  "Towards a formalization of justification and justifiability - Willem Hagemann"
  
- time:  16:00 - 16:30
  name:   "Assuring Increasingly Autonomous Systems in Human-Machine Teams: An Urban Air Mobility Case Study - Siddhartha Bhattacharyya, Jennifer Davis, Anubhav Gupta, Nandith Narayan and Michael Matessa"

- time:  16:30 - 17:00
  name:  "Observable and Attention-Directing BDI Agents for Human-Autonomy Teaming - Blair Archibald, Muffy Calder, Michele Sevegnani and Mengwei Xu"

- time: 17:00 - 17:30
  break: true
  name:  "BREAK"

- time: 17:30 - 18:30
  invited: true
  name: "Invited Talk: Divya Gopinath - Understanding and Verifying Deep Neural Networks  "
  
- time: "18:30"
  close: true
  name: "Day Two Close"


### TALKS ###
show_talks: true
invited_talks:
  - name: Clare Dixon
    bio: "Professor of Computer Science at the University of Manchester (UK) and leader of the Autonomy and Verification research group. Clare's research interests include verification of robot and autonomous systems."
    link: https://www.research.manchester.ac.uk/portal/clare.dixon.html
    title: "Help or Hazard: Towards Verifying Autonomous Robot Systems"
    abstract: "Autonomous robotic systems are being developed to operate in a range of
environments: industrial, transport, healthcare and domestic and have the
potential to be of great benefit to society. Further, they may be assisting,
collaborating with or working near humans. We must make sure they are
safe, robust, reliable and trustworthy and they themselves don't become
become the hazard. In this talk I will discuss ways  to verify
such systems, relating to research carried out over a number of projects with
different types of robot, operating in a range of scenarios."
    video: "https://www.youtube.com/watch?v=qRzROixTcEY&t=10s"

  - name: "Divya Gopinath"
    bio: "Researcher in Formal Verification in the Robust Software Engineering (RSE) group at the NASA Ames Research Center, her research focuses on applying formal methods to analyze and verify neural networks and debug software programs.  Divya is also a member of the FMAS2021 Programme Committee."
    link: https://ti.arc.nasa.gov/profile/dgopinat/
    title: "Understanding and Verifying Deep Neural Networks"
    abstract: "Deep Neural Networks (DNNs) have gained immense popularity in recent times and have widespread use in applications such as image classification,
sentiment analysis, speech recognition and also in safety-critical applications such as autonomous driving. However, they suffer limitations such as lack of explainability and robustness which raise safety and security concerns in their usage. Further, the complex structure and large input spaces of DNNs act as an impediment to thorough verification and testing. The SafeDNN project at the Robust Software Engineering (RSE) group at NASA aims at exploring techniques to ensure that systems that use deep neural networks are safe, robust and interpretable.
In this talk, I will be presenting our technique <a rel='external' href='https://doi.org/10.1109/ASE.2019.00079' >Prophecy<span class='fas fa-external-link-alt'></span></a> that automatically infers formal properties of deep neural network models. The tool extracts patterns based on neuron activations as preconditions that imply certain desirable output properties of the model. I would be highlighting case studies that use Prophecy in obtaining explanations for network decisions, understanding correct and incorrect behavior, providing formal guarantees wrt safety and robustness, and debugging neural network models. We have applied the tool on image classification networks, neural network controllers providing turn advisories in unmanned aircrafts, regression models used for autonomous center-line tracking in aircrafts and neural network object detectors."
    video: "https://www.youtube.com/watch?v=mIJ3yVVy_BM&t=3s"

### PAPERS ###
show_papers: true
papers:
  - title: "Towards Partial Monitoring: It is Always too Soon to Give Up"
    paper_number: 3
    titleLink: http://eptcs.web.cse.unsw.edu.au/paper.cgi?FMAS2021.3
    authors: "Angelo Ferrando and Rafael C. Cardoso"
    abstract: "Runtime Verification is a lightweight formal verification technique. It is used to verify at runtime whether the system under analysis behaves as expected. The expected behaviour is usually formally specified by means of properties, which are used to automatically synthesise monitors. A monitor is a device that, given a sequence of events representing a system execution, returns a verdict symbolising the satisfaction or violation of the formal property. Properties that can (resp. cannot) be verified at runtime by a monitor are called monitorable and non-monitorable, respectively. In this paper, we revise the notion of monitorability from a practical perspective, where we show how non-monitorable properties can still be used to generate partial monitors, which can partially check the properties. Finally, we present the implications both from a theoretical and practical perspectives. "
    slides: "https://github.com/FMASWorkshop/FMASWorkshop.github.io/blob/main/_workshops/2021slides/Ferrando_slides.pdf"


  - title: "Formal Guarantees of Timely Progress for Distributed Knowledge Propagation"
    paper_number: 5
    titleLink: http://eptcs.web.cse.unsw.edu.au/paper.cgi?FMAS2021.5
    authors: "Saswata Paul, Stacy Patterson, and Carlos A. Varela"
    abstract: "Autonomous air traffic management (ATM) operations for urban air mobility (UAM) will
necessitate the use of distributed protocols for decentralized coordination between aircraft.
As UAM operations are time-critical, it will be imperative to have formal guarantees of
progress for the distributed protocols used in ATM. Under asynchronous settings, message
transmission and processing delays are unbounded, making it impossible to provide deterministic
bounds on the time required to make progress. We present an approach for formally
guaranteeing timely progress in a Two-Phase Acknowledge distributed knowledge propagation
protocol by probabilistically modeling the delays using theory about the Multicopy Two-
Hop Relay protocol and the M/M/1 queue model. The guarantee states a probabilistic upper
bound to the time for progress as a function of the probabilities of the total transmission
and processing delays being less than two given values. We also showcase the development
of a library of formal theory in the Athena proof assistant, that is tailored towards reasoning
about timely progress in distributed protocols deployed in airborne networks."
    slides: "https://github.com/FMASWorkshop/FMASWorkshop.github.io/blob/0b9e628287b28f9c7533ada484815c35766296b8/_workshops/2021slides/Paul_slides.pdf"
    
  - title: "Online Strategy Synthesis for Safe and Optimized Control of Steerable Needles"
    paper_number: 9
    titleLink: http://eptcs.web.cse.unsw.edu.au/paper.cgi?FMAS2021.9
    authors: "Sascha Lehmann, Antje Rogalla, Maximilian Neidhardt, Alexander Schlaefer, and Sibylle Schupp"
    abstract: "Autonomous systems are often applied in uncertain environments, which require prospective action planning and retrospective data evaluation for future planning to ensure safe operation. Formal approaches may support these systems with safety guarantees, but are usually expensive and do not scale well with growing system complexity. In this paper, we introduce online strategy synthesis based on classical strategy synthesis to derive formal safety guarantees while reacting and adapting to environment changes. To guarantee safety online, we split the environment into region types which determine the acceptance of action plans and trigger local correcting actions. Using model checking on a frequently updated model, we can then derive locally safe action plans (prospectively), and match the current model against new observations via reachability checks (retrospectively). As use case, we successfully apply online strategy synthesis to medical needle steering, i.e., navigating a (flexible and beveled) needle through tissue towards a target without damaging its surroundings."
    slides: ""
    
  - title: "Extending Urban Multi-Lane Spatial Logic to Formalise Road Junction Rules"
    paper_number: 1
    titleLink: http://eptcs.web.cse.unsw.edu.au/paper.cgi?FMAS2021.1
    authors: "Maike Schwammberger and Gleifer Alves"
    abstract: "During the design of autonomous vehicles (AVs), several stages should include a verification process to guarantee that the AV is driving safely on the roads. One of these stages is to assure the AVs abide by the road traffic rules. To include road traffic rules in the design of an AV, a precise and unambiguous formalisation of these rules is needed. However, only recently this has been pointed out as an issue for the design of AVs and the few works on this only capture the temporal aspects of the rules, leaving behind the spatial aspects. Here, we extend the spatial traffic logic, Urban Multi-lane Spatial Logic, to formalise a subset of the UK road junction rules, where both temporal and spatial aspects of the rules are captured. Our approach has an abstraction level for urban road junctions that could easily promote the formalisation of the whole set of road junction rules and we exemplarily formalise three of the UK road junction rules. Once we have the whole set formalised, we will model, implement, and formally verify the behaviour of an AV against road traffic rules so that guidelines for the creation of a Digital Highway Code for AVs can be established."
    slides: "https://github.com/FMASWorkshop/FMASWorkshop.github.io/blob/0b9e628287b28f9c7533ada484815c35766296b8/_workshops/2021slides/Schwammberger_slides.pdf"
    
  - title: "Simulation and Model Checking for Close to Realtime Overtaking Planning"
    paper_number: 2
    titleLink: http://eptcs.web.cse.unsw.edu.au/paper.cgi?FMAS2021.2
    authors: "Daumantas Pagojus, Alice Miller, Bernd Porr, and Ivaylo Valkov"
    abstract: "Fast and reliable trajectory planning is a key requirement of autonomous vehicles. In this paper we introduce a novel technique for planning the route of an autonomous vehicle on a straight rural road using the Spin model checker. We show how we can combine Spin’s ability to identify paths violating temporal properties with sensor information from a 3D Unity simulation of an autonomous vehicle, to plan and perform consecutive overtaking manoeuvres on a traffic-heavy road. This involves discretising the sensory information and combining multiple sequential Spin models with a Linear Time Temporal Logic specification to generate an error path. This path provides the autonomous vehicle with an action plan. The entire process takes place in close-to real time (using no pre-computed data) and the action plan is specifically tailored for individual scenarios. Our experiments demonstrate that the simulated autonomous vehicle implementing our approach can drive on average at least 40km and overtake 214 vehicles before experiencing a collision – which is usually caused by inaccuracies in the sensory system. While the proposed system has some drawbacks, we believe that our novel approach demonstrates a potentially powerful future tool for efficient trajectory planning for autonomous vehicles."
    slides: "https://github.com/FMASWorkshop/FMASWorkshop.github.io/blob/0b9e628287b28f9c7533ada484815c35766296b8/_workshops/2021slides/Miller_slides.pdf"
    
  - title: "Improving Online Railway Deadlock Detection using a Partial Order Reduction"
    paper_number: 8
    titleLink: http://eptcs.web.cse.unsw.edu.au/paper.cgi?FMAS2021.8
    authors: "Bjørnar Luteberget"
    abstract: "Although railway dispatching on large national networks is gradually becoming
more computerized, there are still major obstacles to retrofitting
(semi-)autonomous control systems. In addition to requiring extensive and
detailed digitalization of infrastructure models and information systems, exact
optimization for railway dispatching is computationally hard. Heuristic
algorithms and manual overrides are likely to be required for semi-autonomous
railway operations for the foreseeable future.

In this context, being able to detect problems such as deadlocks can be a
valuable part of a runtime verification system. If bound-for-deadlock situations
are correctly recognized as early as possible, human operators will have more
time to better plan for recovery operations. Deadlock detection may also be
useful for verification in a feedback loop with a heuristic or semi-autonomous
dispatching algorithm if the dispatching algorithm cannot itself guarantee a
deadlock-free plan.

We describe a SAT-based planning algorithm for online detection of
bound-for-deadlock situations. The algorithm exploits parallel updates of train
positions and a partial order reduction technique to significantly reduce the
number of state transitions (and correspondingly, the sizes of the formulas) in
the SAT instances needed to prove whether a deadlock situation is bound to
happen in the future. Implementation source code and benchmark instances are
supplied, and a direct comparison against another recent study demonstrates
significant performance gains."
    slides: "https://github.com/FMASWorkshop/FMASWorkshop.github.io/blob/0b9e628287b28f9c7533ada484815c35766296b8/_workshops/2021slides/Luteberget_slides.pdf"
    
  - title: "Observable and Attention-Directing BDI Agents for Human-Autonomy Teaming"
    paper_number: 12
    titleLink: http://eptcs.web.cse.unsw.edu.au/paper.cgi?FMAS2021.12
    authors: "Blair Archibald, Muffy Calder, Michele Sevegnani, and Mengwei Xu"
    abstract: "Human-autonomy teaming (HAT) scenarios feature humans and autonomous agents collaborating to meet a shared goal. For effective collaboration, the agents must be transparent and able to share important information about their operation with human teammates. We address the challenge of transparency for Belief-Desire-Intention agents defined in the Conceptual Agent Notation (CAN) language. We extend the semantics to model agents that are observable (i.e. the internal state of tasks is available), and attention-directing (i.e. specific states can be flagged to users), and provide an executable semantics via an encoding in Milner's bigraphs. Using an example of unmanned aerial vehicles, the BigraphER tool, and PRISM, we show and verify how the extensions work in practice."
    slides: "https://github.com/FMASWorkshop/FMASWorkshop.github.io/blob/0b9e628287b28f9c7533ada484815c35766296b8/_workshops/2021slides/Mengwei_slides.pdf"
    
  - title: "Towards a formalization of justification and justifiability"
    paper_number: 10
    titleLink: http://eptcs.web.cse.unsw.edu.au/paper.cgi?FMAS2021.10
    authors: "Willem Hagemann"
    abstract: "We introduce the logic QKSD which is a normal multi-modal logic over finitely many modalities that additionally supports bounded quantification of modalities. An important feature of this logic is that it allows to quantify over the information components of systems. It can be used to derive justifcations and has a notion of justifiability. We also report on a prototypical implementation of a
satisfiability solver of this logic and shows some examples."
    slides: "https://github.com/FMASWorkshop/FMASWorkshop.github.io/blob/0b9e628287b28f9c7533ada484815c35766296b8/_workshops/2021slides/Hagemann_slides.pdf"
    
  - title: "Complete Agent-driven Model-based System Testing for Autonomous Systems"
    paper_number: 4
    titleLink: http://eptcs.web.cse.unsw.edu.au/paper.cgi?FMAS2021.4
    authors: "Kerstin Eder, Wen-Ling Huang, and Jan Peleska"
    abstract: "In this position paper, a novel approach to testing complex autonomous transportation systems (ATS) in the
automotive, avionic, and railway domains is described. It is well-suited to overcome the problems of verification and validation (V&V) effort which is known to become infeasible for complex ATS, when trying to perform V&V with conventional methods. The approach advocated here uses complete testing methods on module level, because these establish formal proofs
for the logical correctness of the software. Having established
logical correctness, system-level tests are performed in simulated cloud environments and on the target system. To give evidence that ``sufficiently many'' system tests have been performed with the target system, a formally justified coverage criterion is introduced. To optimise the execution of very large system test suites, we advocate an online testing approach where multiple tests are executed in parallel, and test steps are identified on-the-fly. The coordination and optimisation of these executions is achieved by an agent-based approach. Each aspect of the testing approach advocated here is shown to be consistent with existing standards for development and V&V of safety-critical transportation systems, or it is justified why
they should become acceptable in future revisions of the applicable standards."
    slides: "https://github.com/FMASWorkshop/FMASWorkshop.github.io/blob/0b9e628287b28f9c7533ada484815c35766296b8/_workshops/2021slides/Peleska_slides.pdf"
    
  - title: "Assuring Increasingly Autonomous Systems in Human-Machine Teams: An Urban Air Mobility Case Study"
    paper_number: 11
    titleLink: http://eptcs.web.cse.unsw.edu.au/paper.cgi?FMAS2021.11
    authors: "Siddhartha Bhattacharyya, Jennifer Davis, Anubhav Gupta, Nandith Narayan, and Michael Matessa"
    abstract: "As aircraft systems become increasingly autonomous, the human-machine role allocation changes and opportunities for new failure modes arise. This necessitates an approach to identify the safety requirements for the increasingly autonomous system (IAS) as well as a framework and techniques to verify and validate that the IAS meets its safety requirements. We use Crew Resource Management techniques to identify requirements and behaviors for safe human-machine teaming behaviors. We provide a methodology to verify that an IAS meets its requirements. We apply the methodology to a case study in Urban Air Mobility, which includes two contingency scenarios: unreliable sensor and aborted landing. For this case study, we implement an IAS agent in the Soar language that acts as a copilot for the selected contingency scenarios and performs takeoff and landing preparation, while the pilot maintains final decision authority. We develop a formal human-machine team architecture model in the Architectural Analysis and Design Language (AADL), with operator and IAS requirements formalized in the Assume Guarantee REasoning Environment (AGREE) Annex to AADL. We formally verify safety requirements for the human-machine team given the requirements on the IAS and operator. We develop an automated translator from Soar to the nuXmv model checking language and formally verify the IAS requirements for the IAS agent using nuXmv. We share the design and requirements errors found in the process as well as our lessons learned."
    slides: "https://github.com/FMASWorkshop/FMASWorkshop.github.io/blob/0b9e628287b28f9c7533ada484815c35766296b8/_workshops/2021slides/Siddhartha_slides.pdf"
    
  - title: "QuantifyML: How good is my machine learning model?"
    paper_number: 6
    titleLink: http://eptcs.web.cse.unsw.edu.au/paper.cgi?FMAS2021.6
    authors: "Muhammad Usman, Divya Gopinath, and Corina S. Pasareanu"
    abstract: "The efficacy of machine learning models is typically determined by computing their accuracy on test data sets. However, this may often be misleading, since the test data may not be representative of the problem that is being studied. With QuantifyML we aim to precisely quantify the extent to which machine learning models have learned and generalized from the given data. Given a trained model, QuantifyML translates it into a C program and feeds it to the CBMC model checker to produce a formula in Conjunctive Normal Form (CNF). The formula is analyzed with off-the-shelf model counters to obtain precise counts with respect to different model behavior. QuantifyML enables i) evaluating learnability by comparing the counts for the outputs to ground truth, expressed as logical predicates, ii) comparing the performance of models built with different machine learning algorithms (decision-trees vs. neural networks), and iii) quantifying the safety and robustness of models."
    slides: ""
    
  - title: "Complete Test of Synthesised Safety Supervisors for Robots and Autonomous Systems"
    paper_number: 7
    titleLink: http://eptcs.web.cse.unsw.edu.au/paper.cgi?FMAS2021.7
    authors: "Mario Gleirscher and Jan Peleska"
    abstract: "Verified controller synthesis uses world models that comprise all potential behaviours of humans, robots, further equipment, and the controller to be synthesised. A world model enables quantitative risk assessment, for example, by stochastic model checking. Such a model describes a range of controller behaviours some of which---when implemented correctly---guarantee that the overall risk in the actual world is acceptable, provided that the stochastic assumptions have been made to the safe side. Synthesis then selects an acceptable-risk controller behaviour. However, because of crossing abstraction, formalism, and tool boundaries, verified synthesis for robots and autonomous systems has to be accompanied by rigorous testing. In general, standards and regulations for safety-critical systems require testing as a key element to obtain certification credit before entry into service. This work-in-progress paper presents an approach to the complete testing of synthesised supervisory controllers that enforce safety properties in domains such as human-robot collaboration and autonomous driving. Controller code is generated from the selected controller behaviour. The code generator, however, is hard, if not infeasible, to verify in a formal and comprehensive way. Instead, utilising testing, an abstract test reference is generated, a symbolic finite state machine with simpler semantics than code semantics. From this reference, a complete test suite is derived and applied to demonstrate the observational equivalence between the test reference and the controller code."
    slides: "https://github.com/FMASWorkshop/FMASWorkshop.github.io/blob/1d5f3fe5c72010cd203cbd76d6e7ef4e89c65dcf/_workshops/2021slides/Gleirscher_slides.pdf"

### DATES ###
dates:
  submission: "~~30th of July 2021~~ 13th of August 2021"
  notification: "~~3rd of September 2021~~ 17th of September 2021"
  final_version: "~~24th of September 2021~~ 8th of October 2021"
  workshop: "21st and 22nd of October 2021"

### PROGRAMME COMMITTEE ###
show_pc : true
pc :
  - first_name: Alvaro
    last_name: Miyazawa
    affiliation: University of York (UK)
    link: https://www-users.cs.york.ac.uk/~alvarohm/

  - first_name: Anastasia
    last_name: Mavridou
    affiliation: NASA Ames Research Center (USA)
    link: http://amavridou.com/

  - first_name: Angelo
    last_name: Ferrando
    affiliation: 	University of Genova (Italy)
    link: https://angeloferrando.github.io/website/

  - first_name: Claudio
    last_name: Menghi
    affiliation: University of Luxembourg (Luxembourg)
    link: https://claudiomenghi.github.io/index.html

  - first_name: Dominique
    last_name: Méry
    affiliation: Université de Lorraine (France)
    link: https://members.loria.fr/Mery/

  - first_name: Hao
    last_name: Wu
    affiliation: 	Maynooth University (Ireland)
    link: http://www.cs.nuim.ie/~haowu/

  - first_name: Jérémie
    last_name: Guiochet
    affiliation: University of Toulouse (France)
    link: http://homepages.laas.fr/guiochet/

  - first_name: Maike
    last_name: Schwammberger
    affiliation: University of Oldenberg (Germany)
    link: https://uol.de/en/csd/persons-contacts/maike-schwammberger-msc/

  - first_name: Marija
    last_name: Slavkovik
    affiliation: University of Bergen (Norway)
    link: http://slavkovik.com/index.html

  - first_name: Rafael C.
    last_name: Cardoso
    affiliation: University of Manchester (UK)
    link: https://rafaelcaue.github.io/

  - first_name: Raluca
    last_name: Lefticaru
    affiliation: University of Bradford (UK)
    link: https://ralucalefticaru.github.io/

  - first_name: Rob
    last_name: Hierons
    affiliation: University of Sheffield (UK)
    link: https://www.sheffield.ac.uk/dcs/people/academic/rob-hierons

  - first_name: Silvia Lizeth
    last_name: 	Tapia Tarifa
    affiliation: University of Oslo (Norway)
    link: https://www.mn.uio.no/ifi/english/people/aca/sltarifa/index.html

  - first_name: Sven
    last_name: Linker
    affiliation: University of Lancaster Leipzig (Germany)
    link: https://orcid.org/0000-0003-2913-7943

  - first_name: Taylor T.
    last_name: Johnson
    affiliation: Vanderbilt University (USA) (USA)
    link: http://www.taylortjohnson.com/

  - first_name: Christopher
    last_name: Bischopink
    affiliation: University of Oldenburg (Germany)
    link: https://uol.de/en/csd/persons-contacts/christopher-bischopink-msc/

  - first_name: Laura
    last_name: Titolo
    affiliation: National Institute of Aerospace (USA)
    link: https://lauratitolo.github.io/

  - first_name: Mallory S.
    last_name: Graydon
    affiliation: NASA Langley Research Center (USA)
    link: https://shemesh.larc.nasa.gov/people/msg/

  - first_name: Stylianos Stelios
    last_name: Basagiannis
    affiliation: Collins Advanced Technology Centre (Ireland)
    link: https://www.linkedin.com/in/stylianos-basagiannis-35080550/

  - first_name: Divya
    last_name: Gopinath
    affiliation: NASA Ames Research Center (USA)
    link: https://ti.arc.nasa.gov/profile/dgopinat/

  - first_name: Michael
    last_name: Fisher
    affiliation: University of Manchester (UK)
    link: https://personalpages.manchester.ac.uk/staff/michael.fisher/

  - first_name: Ivan
    last_name: Perez
    affiliation: NASA Langley/National Institute of Aerospace (USA)
    link: https://www.linkedin.com/in/ivanperezdominguez/

  - first_name: Louise A.
    last_name: Dennis
    affiliation: University of Manchester (UK)
    link: http://www.cs.man.ac.uk/~dennisl/

  - first_name: Mario
    last_name: Gleirscher
    affiliation: University of Bremen (Germany)
    link: http://www.gleirscher.at/mg/

  - first_name: Colin
    last_name: Paterson
    affiliation: University of York (UK)
    link: https://www.linkedin.com/in/colin-paterson-158374a0/?originalSubdomain=uk

  - first_name: Alice
    last_name: Miller
    affiliation: University of Glasgow (UK)
    link: https://www.gla.ac.uk/schools/computing/staff/alicemiller/

  - first_name: Georgios
    last_name: Giantamidis
    affiliation: Collins Advanced Technology Centre (Ireland)
    link:

  - first_name: Chiara
    last_name: Picardi
    affiliation: University of York (UK)
    link:

  - first_name: Rosemary
    last_name: Monahan
    affiliation: Maynooth University (Ireland)
    link: http://rosemarymonahan.com/
  - first_name: Lina
    last_name: Marsso
    affiliation: University of Toronto (Canda)
    link: http://convecs.inria.fr/people/Lina.Marsso/
#  - first_name:
#    last_name:
#    affiliation:
#    link:


register : https://www.eventbrite.co.uk/e/third-workshop-on-formal-methods-for-autonomous-systems-fmas-2021-tickets-177959861737

easychair : https://easychair.org/conferences/?conf=fmas2021
