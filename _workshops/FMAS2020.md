---
layout: page
title: "Second Workshop on Formal Methods for Autonomous Systems"
acronym : "FMAS 2020"
date : 2020-12-07
permalink: /FMAS2020/
image: /images/logos/FMAS-Logo.png
---


 <img alt="FMAS Workshop Logo" style="float: left; margin: 1em" src="{{site.images}}logos/FMAS-Logo.png">


This one day workshop will bring together researchers working on a range of techniques for formal verification or autonomous systems,
to present recent work in the area, discuss key difficulties, and stimulate collaboration between the robotics and formal methods
communities. This workshop will include invited speakers, contributed papers, and experience reports.

FMAS 2020 will be held **online**, due to the ongoing disruption caused by COVID-19. Since many of the conferences that we were looking to for hosting the workshop are not accepting satellite events, FMAS 2020 will run stand-alone.

## Scope

Autonomous -- and Robotic -- Systems present unique challenges for formal methods. They are embodied entities that can interact with
the real world and make autonomous decisions. Amongst others, they can be viewed as safety-critical, cyber-physical, hybrid, and real-time systems.
Key issues for formal methods applied to autonomous systems include capturing how the system will deal with a dynamic external environment
and verification of the system's decision making capabilities -- including planning, ethical, and reconfiguration choices. Some autonomous
systems require certification before deployment, others require public trust for wide adoption; both of these scenarios are being tackled
by formal methods.

The goals of this workshop are to bring together leading researchers in this area to present recent and ongoing work, including
experience reports and case studies as well as identify future directions for this emerging application of formal methods.
This workshop is concerned with the use of formal methods to specify, model, or verify autonomous or robotic systems; in whole or in part.
Submissions may focus on case studies that identify the challenges for formal methods in this area, or experience reports that provide guidelines
for tackling these challenges.

We are especially interested in work using integrated formal methods, discussing the future directions of the field, using Runtime Verification or other approaches to deal with the _reality gap_, the cross over of safety and security, and verification of systems against safety assurance arguments or standards documents.





## Programme Information

Below you can find the link to the [proceedings](#proceedings) and the details of the [invited talks](#invited-talks).

The details of the papers accepted at FMAS 2020 and the presentation videos from the workshop, are available in the [Accepted Papers](#accepted-papers) section.

### Proceedings

The proceedings for FMAS2020 are available online via {% include ext_link.html text="EPTCS" link="http://eptcs.web.cse.unsw.edu.au/content.cgi?FMAS2020" %}. We would like to thank our editor and the rest of the team at EPTCS for their help with publishing these proceedings.

### Invited Talks

<style> .talk-title {font-style: italic; } </style>
<style> .talk-details{ list-style-type: none; } </style>

There were two invited speakers for FMAS 2020.

* Ivan Perez is a research scientist at the National Institute of Aerospace,
and has been a member of the NASA Formal Methods Group since 2018. As a
contractor assigned to NASA Langley Research Center, he investigates the application of formal methods to problems in aerospace, with particular focus on runtime verification of unmanned aerial vehicles. In the past, Dr. Perez also worked as a programmer and researcher for the High Performance Computing Center (Germany), IMDEA Software (Spain), the Technical University of Madrid (Spain), and the University of Twente (Netherlands), as well as for multiple functional programming companies. Dr. Perez completed his PhD in Computer Science at the University of Nottingham (UK), which focused on testing and functional programming applied to games and user interfaces. He also holds a Master's Degree in Computational Logic and a Degree of Engineer in Computer Science, both from the Technical University of Madrid.

<ul class="talk-details">
<li> <b>Title</b> : <span class="talk-title"> Runtime Verification with Copilot 3 </span> </li>
<li> <b>Abstract</b>: Ultra-critical systems require high-level assurance, which cannot always be
guaranteed in compile time. The use of runtime verification (RV) enables
monitoring these systems in runtime, to detect property violations early and
limit their potential consequences. However, the introduction of monitors in
ultra-critical systems poses a challenge, as failures and delays in the RV
subsystem could affect other subsystems and threaten the mission as a whole.

In this talk we present Copilot 3, a runtime verification framework for
real-time embedded systems. Copilot monitors are written in a compositional,
stream-based language with support for a variety of Temporal Logics (TL), which
results in robust, high-level specifications that are easier to understand than
low-level imperative implementations. The framework then translates monitor
specifications into C code with static memory requirements, which can be
compiled to run on embedded hardware.

We also discuss how Copilot has been used in experimental research by NIA, NASA
and other organizations, its place in relation to other RV frameworks, and
possible future directions for RV in autonomous systems.</li>
</ul>

* {% include ext_link.html text="Louise Dennis" link="https://www.research.manchester.ac.uk/portal/louise.dennis.html" %} is from the University of Manchester. Her background is in artificial intelligence and more specifically in agent and autonomous systems and automated reasoning. She has worked on the development of several automated reasoning and theorem proving tools, most notably the Agent JPF model checker for BDI agent languages; the lambda-clam proof planning system; and the PROSPER Toolkit for integrating an interactive theorem prover (HOL) with automated reasoning tools (such as SAT solvers) and Case/CAD tools. More recently she has investigated rational agent programming languages and architectures for autonomous systems, with a particular emphasis on verifiable systems and ethical reasoning.

<ul class="talk-details">
<li> <b>Title</b> : <span class="talk-title"> Verifying Machine Ethics </span> </li>
<li> <b>Abstract</b>: Machine ethics is concerned with the challenge of constructing ethical and ethically behaving artificial agents and systems.  One important theme within machine ethics concerns explicitly ethical agents â€“ those which are not ethical simply because they are constrained by their programming or deployment to be so but which use a concept of ethics in some way as part of their operation.  Normally this requires the provision of rules, utilities or priorities by a programmer, knowledge engineer or user.  In this talk I will address the question of how such explicitly ethical programs can be verified.  What kind of properties can we consider and what kind of errors might we find?</li>
</ul>



### Accepted Papers

<style> .paper-title {font-style: italic; } </style>
<style> .paper-details{ list-style-type: none; } </style>

We accepted the following papers for FMAS 2020.

* <span class="paper-title">{% include ext_link.html text="How to Formally Model Human in Collaborative Robotics" link="http://eptcs.web.cse.unsw.edu.au/paper.cgi?FMAS2020.1" %}</span>
<ul class="paper-details">
<li> <b>Authors:</b> <a href="https://askarpour.github.io/">Mehrnoosh Askarpour </a> </li>
<li> <b>Abstract:</b> Human-robot collaboration (HRC) is an emerging trend of robotics that promotes the co-presence and cooperation of humans and robots in common workspaces.
Physical vicinity and interaction between humans and robots, combined with the uncertainty of human behavior, could lead to undesired situations where humans are injured. Thus, safety is a primary priority for HRC applications.

Safety analysis via formal modeling and verification techniques could considerably avoid dangerous consequences, but only if the models of HRC systems are comprehensive and good enough, which requires reasonably realistic models of human behavior. This paper explores state-of-the-art solutions for modeling human and discusses which ones are suitable for HRC scenarios.
</li>
<li>
Video: <a href="https://github.com/FMASWorkshop/FMAS-Archive/raw/main/FMAS2020/Askarpour-How_to_Formally_Model_Human_%20in_Collaborative_Robotics_720.m4v" download="" > <button type="button" > Download </button></a>
</li>
</ul>

* <span class="paper-title">{% include ext_link.html text="Towards Compositional Verification for Modular Robotic Systems" link="http://eptcs.web.cse.unsw.edu.au/paper.cgi?FMAS2020.2" %}</span>
<ul class="paper-details">  
<li> <b>Authors:</b> <a href="https://rafaelcaue.github.io/">Rafael C. Cardoso </a>, <a href="http://www.cs.man.ac.uk/~dennisl">Louise A. Dennis </a>, Marie Farrell,  <a href="https://web.cs.manchester.ac.uk/~michael/">Michael Fisher</a>, and Matt Luckcuck  </li>
<li> <b>Abstract:</b> Software engineering of modular robotic systems is a challenging task, however, verifying that the developed components all behave as they should individually and as a whole presents its own unique set of challenges. In particular, distinct components in a modular robotic system often require different verification techniques to ensure that they behave as expected. Ensuring whole system consistency when individual components are verified using a variety of techniques and formalisms is difficult. This paper discusses how to use compositional verification to integrate the various verification techniques that are applied to modular robotic software, using a First-Order Logic (FOL) contract that captures each component's assumptions and guarantees. These contracts can then be used to guide the verification of the individual components, be it by testing or the use of a formal method.
In this paper, we provide an example of the former using an illustrative example of an autonomous robot used in remote inspection. We also discuss a way of defining a confidence metric for the verification associated with each component.
</li>
<li>
Video: <a href="https://github.com/FMASWorkshop/FMAS-Archive/raw/main/FMAS2020/Cardoso-Towards_Compositional_Verification_for_Modular_Robotic_Systems_720.m4v" download="" > <button type="button" > Download </button></a>
</li>
</ul>

* <span class="paper-title">{% include ext_link.html text="From Requirements to Autonomous Flight: An Overview of the Monitoring ICAROUS Project" link="http://eptcs.web.cse.unsw.edu.au/paper.cgi?FMAS2020.3" %}</span>
<ul class="paper-details">
<li> <b>Authors:</b> <a href="http://shemesh.larc.nasa.gov/people/amd/">Aaron Dutle</a>, <a href="http://shemesh.larc.nasa.gov/people/cam">Cesar Munoz</a>, Esther Conrad, Alwyn Goodloe, Laura Titolo, Ivan Perez, Swee Balachandran, Dimitra Giannakopoulou, Anastasia Mavridou and Thomas Pressburger  </li>
<li> <b>Abstract:</b> The Independent Configurable Architecture for Reliable Operations of Unmanned Systems (ICAROUS) is a software architecture incorporating a set of algorithms to enable autonomous operations of unmanned aircraft applications. This paper provides an overview of Monitoring ICAROUS, a project whose objective is to provide a formal approach to generating runtime monitors for autonomous systems from requirements written in a structured natural language. This approach integrates FRET, a formal requirement elicitation and authoring tool, and Copilot, a runtime verification framework. FRET is used to specify formal requirements in structured natural language. These requirements are translated into temporal logic formulae. Copilot is then used to generate executable runtime monitors from these temporal logic specifications. The generated monitors are directly integrated into ICAROUS to perform runtime verification during flight.
</li>
<li>
Video: <a href="https://github.com/FMASWorkshop/FMAS-Archive/raw/main/FMAS2020/Dutle-From_Requirements_to_Autonomous_Flight_720.m4v" download="" > <button type="button" > Download </button></a>
</li>
</ul>


* <span class="paper-title">{% include ext_link.html text="YAP: Tool Support for Deriving Safety Controllers from Hazard Analysis and Risk Assessments" link="http://eptcs.web.cse.unsw.edu.au/paper.cgi?FMAS2020.4" %}</span>
<ul class="paper-details">
<li> <b>Authors:</b> Mario Gleirscher</li>
<li> <b>Abstract:</b> This tool paper provides a brief overview of YAP, a research tool for risk modelling and discrete-event safety controller design. For an example from the collaborative robotics domain, it is illustrated how one can use YAP in combination with the stochastic model checker PRISM to derive, verify, and synthesise controllers responsible for switching between activities and safety modes.
</li>
<li>
Video: <a href="https://github.com/FMASWorkshop/FMAS-Archive/raw/main/FMAS2020/Gleirscher-YAP720.m4v" download="" > <button type="button" > Download </button></a>
</li>
</ul>


* <span class="paper-title"> {% include ext_link.html text="A Formal Model for Quality-Driven Decision Making in Self-Adaptive Systems" link="http://eptcs.web.cse.unsw.edu.au/paper.cgi?FMAS2020.5" %} </span>
<ul class="paper-details">
<li> <b>Authors:</b> Fatma Kachi, Chafia Bouanaka, and Souheir Merkouche </li>
<li> <b>Abstract:</b>  Maintaining an acceptable level of quality of service in modern complex systems is challenging and particularly in presence of various forms of uncertainty caused by changing execution context, unpredicted events, etc. Self-adaptability is a well-established approach for modelling such systems, and thus enabling them to achieve functional and/or quality of service objectives by autonomously modifying their behavior at runtime. Guaranteeing a continuous satisfaction of quality objectives needs a rigorous definition and analysis of system behavioral properties. Formal methods constitute a promising and effective solution in this direction in order to rigorously specify mathematical models of a software system in general and analyze its behavior in particular. They are also largely adopted to analyze and provide guarantees on the required properties of self-adaptive systems. Therefore, we introduce in the present work a formal model for quality-driven self-adaptive systems under uncertainty. We combine high-level Petri nets and plausible Petri nets in order to model complex data structures enabling system quality attributes quantification and to improve the decision-making process through selecting the most plausible plans with regard to the system actual context.
</li>
<li>
Video: <a href="https://github.com/FMASWorkshop/FMAS-Archive/raw/main/FMAS2020/Kachi-A_Formal_Model_for_Quality-Driven_Decision_Making_in_Self-Adaptive_Systems_720.m4v" download="" > <button type="button" > Download </button></a>
</li>
</ul>

## Chairs

<article style="display:grid">
<section  markdown="1" style="grid-column:1" >
{% include ext_link.html text="Dr Marie Farrell" link="https://orcid.org/0000-0001-7708-3877" %}, University of Manchester, UK
</section>

<section  style="grid-column:2">
{% include ext_link.html text="Dr Michael Fisher" link="https://personalpages.manchester.ac.uk/staff/michael.fisher/" %}, University of Manchester, UK
</section>

<section  style="grid-column:3">
{% include ext_link.html text="Dr Matt Luckcuck" link="https://orcid.org/0000-0002-6444-9312" %}, University of Manchester, UK
</section>

</article>


## Program Committee

* [Christopher Bischopink](https://uol.de/en/csd/persons-contacts/christopher-bischopink-msc/), University of Oldenburg (Germany)
* [Rafael C. Cardoso](https://rafaelcaue.github.io/), University of Manchester (UK)
* [Angelo	Ferrando](https://angeloferrando.github.io/website/), University of Manchester (UK)
* [Mallory S. Graydon](https://shemesh.larc.nasa.gov/people/msg/), NASA (USA)
* [JÃ©rÃ©mie Guiochet](http://homepages.laas.fr/guiochet/), University of Toulouse (France)
* [Rob	Hierons](https://www.sheffield.ac.uk/dcs/people/academic/rob-hierons), University of Sheffield (UK)
* [Taylor T. Johnson](http://www.taylortjohnson.com/), Vanderbilt University (USA)
* [Bruno Lacerda](https://ori.ox.ac.uk/ori-people/bruno-lacerda/), Oxford University (UK)
* [Raluca	Lefticaru](https://ralucalefticaru.github.io/), University of Bradford	(UK)
* [Sven	Linker](https://orcid.org/0000-0003-2913-7943), Lancaster University Leipzig (Germany)
* [Anastasia Mavridou](http://amavridou.com/), SGT Inc./NASA Ames Research Center (USA)
* [Claudio Menghi](https://claudiomenghi.github.io/index.html), University of Luxembourg (Luxembourg)
* [Dominique MÃ©ry](https://members.loria.fr/Mery/), UniversitÃ© de Lorraine, LORIA (France)
* [Alice Miller](https://www.gla.ac.uk/schools/computing/staff/alicemiller/), University of Glasgow (UK)
* [Alvaro	Miyazawa](https://www-users.cs.york.ac.uk/~alvarohm/), University of York (UK)
* [Rosemary Monahan](http://rosemarymonahan.com/), Maynooth University (Ireland)
* [Ivan Perez](https://www.linkedin.com/in/ivanperezdominguez/), NIA/NASA Langley Research Center (USA)
* [Maike Schwammberger](https://uol.de/en/csd/persons-contacts/maike-schwammberger-msc/), University of Oldenburg (Germany)
* [Silvia Lizeth	Tapia Tarifa](https://www.mn.uio.no/ifi/english/people/aca/sltarifa/index.html),	University of Oslo (Norway)
* [Laura	Titolo](https://lauratitolo.github.io/),	National Institute of Aerospace (USA)
* [Hao	Wu](http://www.cs.nuim.ie/~haowu/),	Maynooth University (Ireland)
